#' @include FamiliarS4Generics.R
#' @include FamiliarS4Classes.R
NULL


.get_available_data_elements <- function(check_has_estimation_type=FALSE, check_has_detail_level=FALSE){
  
  # All data elements.
  all_data_elements <- c("auc_data", "calibration_data", "confusion_matrix", "decision_curve_analyis", "feature_expressions",
                         "fs_vimp", "hyperparameters", "kaplan_meier_data", "model_performance",
                         "model_vimp", "mutual_correlation", "permutation_vimp", "prediction_data",
                         "stratification_data", "univariate_analysis")
  
  # Data elements that allow setting an estimation type.
  can_set_estimation_type <- c("auc_data", "decision_curve_analyis", "model_performance", "permutation_vimp",  "prediction_data")
  
  # Data elements that allow setting a detail level.
  can_set_detail_level <- c(can_set_estimation_type, "confusion_matrix")
  
  if(check_has_estimation_type){
    all_data_elements <- intersect(all_data_elements, can_set_estimation_type)
    
  } 
  
  if(check_has_detail_level){
    all_data_elements <- intersect(all_data_elements, can_set_detail_level)
  }
  
  return(all_data_elements)
}



.parse_detail_level <- function(x, default, data_element){
  
  if(is.null(x) | is.waive(x)) return(default)
  
  # detail level is stored in a list, by data_element.
  if(is.list(x)) x <- x[[data_element]]
  
  if(is.null(x)) return(default)
  
  .check_parameter_value_is_valid(x=x, var_name="detail_level",
                                  values=c("ensemble", "hybrid", "model"))
  
  return(x)
}



.parse_estimation_type <- function(x, default, data_element, detail_level, has_internal_bootstrap){
  
  # Change to default to point if the detail_level is model.
  if(detail_level == "model") default <- "point"
  
  # In case there is no internal bootstrap, we can only determine point
  # estimates for ensemble and model detail levels (but potentially more for
  # hybrid).
  if(!has_internal_bootstrap & detail_level %in% c("ensemble", "model") & default != "point") default <- "point"
  
  if(is.null(x) | is.waive(x)) return(default)
  
  # detail level is stored in a list, by data_element.
  if(is.list(x)) x <- x[[data_element]]
  
  if(is.null(x)) return(default)
  
  .check_parameter_value_is_valid(x=x, var_name="estimation_type",
                                  values=c("point", "bias_correction", "bc", "bootstrap_confidence_interval", "bci"))
  
  return(x)
}



.parse_aggregate_results <- function(x, default, data_element){
  
  if(is.null(x) | is.waive(x)) return(default)
  
  # detail level is stored in a list, by data_element.
  if(is.list(x)) x <- x[[data_element]]
  
  if(is.null(x)) return(default)
  
  x <- tolower(x)
  .check_parameter_value_is_valid(x=x, var_name="aggregate_results",
                                  values=c("true", "false", "none", "all", "default"))
  
  if(x == "default") return(default)
  if(x %in% c("true", "all")) return(TRUE)
  
  return(FALSE)
}




#'@title Internal function to create a familiarData object.
#'
#'@description Compute various data related to model performance and calibration
#'  from the provided dataset and `familiarEnsemble` object and store it as a
#'  `familiarData` object.
#'
#'@param object A `familiarEnsemble` object, which is an ensemble of one or more
#'  `familiarModel` objects.
#'@param data A `dataObject` object, `data.table` or `data.frame` that
#'  constitutes the data that are used to compute
#'@param is_pre_processed Flag that indicates whether the data was already
#'  pre-processed externally, e.g. normalised and clustered. Only used if the
#'  `data` argument is a `data.table` or `data.frame`.
#'@param cl Cluster created using the `parallel` package. This cluster is then
#'  used to speed up computation through parallelisation.
#'@param time_max Time point which is used as the benchmark for e.g. cumulative
#'  risks generated by random forest, or the cutoff for Uno's concordance index.
#'  If not provided explicitly, this parameter is read from settings used at
#'  creation of the underlying `familiarModel` objects. Only used for `survival`
#'  outcomes.
#'@param eval_times One or more time points that are used for assessing
#'  calibration in survival problems. This is done as expected and observed
#'  survival probabilities depend on time. If not provided explicitly, this
#'  parameter is read from settings used at creation of the underlying
#'  `familiarModel` objects. Only used for `survival` outcomes.
#'@param aggregation_method Method for aggregating variable importances for the
#'  purpose of evaluation. Variable importances are determined during feature
#'  selection steps and after training the model. Both types are evaluated, but
#'  feature selection variable importance is only evaluated at run-time.
#'
#'  See the documentation for the `vimp_aggregation_method` argument in
#'  `summon_familiar` for information concerning the different available
#'  methods.
#'
#'  If not provided explicitly, this parameter is read from settings used at
#'  creation of the underlying `familiarModel` objects.
#'@param rank_threshold The threshold used to  define the subset of highly
#'  important features during evaluation.
#'
#'  See the documentation for the `vimp_aggregation_rank_threshold` argument in
#'  `summon_familiar` for more information.
#'
#'  If not provided explicitly, this parameter is read from settings used at
#'  creation of the underlying `familiarModel` objects.
#'@param ensemble_method Method for ensembling predictions from models for the
#'  same sample. Available methods are:
#'
#'  * `mean`: Use the mean of the predicted values as the ensemble value for a
#'  sample.
#'@param stratification_ensemble_method Method for ensembling the risk group
#'  assignments from different models for the same sample.
#'
#'  The following methods are available:
#'
#'  * `ensemble_mean`: Risk groups are determined for each sample using the
#'  threshold values of the different models in the ensemble. The risk groups
#'  are treated as ordinal and encoded using integer values. The mean of the
#'  encoded values is computed. The risk group bin containing the mean value is
#'  then used as the ensemble-based risk group.
#'
#'  * `ensemble_mode` (default): Risk groups are determined for each sample
#'  using the threshold values of the different models in the ensemble. The most
#'  commonly assigned risk group is then used as the ensemble-based risk group.
#'
#'  * `median_threshold`: The median threshold value for each risk group is
#'  determined from the threshold values of the different models in the
#'  ensemble. The resulting threshold(s) are then applied to the ensemble
#'  prediction of a sample to identify the ensemble-based risk group.
#'
#'  * `mean_threshold`: Similar to `median_threshold`, but uses the mean
#'  threshold value for each risk group.
#'
#'  If not provided explicitly, this parameter is read from settings used at
#'  creation of the underlying `familiarModel` objects. This parameter is only
#'  relevant for `survival` outcomes.
#'@param metric One or more metrics for assessing model performance. See the
#'  vignette on performance metrics for the available metrics. If not provided
#'  explicitly, this parameter is read from settings used at creation of the
#'  underlying `familiarModel` objects.
#'@param feature_cluster_method The method used to perform clustering. These are
#'  the same methods as for the `cluster_method` configuration parameter:
#'  `none`, `hclust`, `agnes`, `diana` and `pam`.
#'
#'  `none` cannot be used when extracting data regarding mutual correlation or
#'  feature expressions.
#'
#'  If not provided explicitly, this parameter is read from settings used at
#'  creation of the underlying `familiarModel` objects.
#'
#'@param feature_linkage_method The method used for agglomerative clustering in
#'  `hclust` and `agnes`. These are the same methods as for the
#'  `cluster_linkage_method` configuration parameter: `average`, `single`,
#'  `complete`, `weighted`, and `ward`.
#'
#'  If not provided explicitly, this parameter is read from settings used at
#'  creation of the underlying `familiarModel` objects.
#'
#'@param feature_cluster_cut_method The method used to divide features into
#'  separate clusters. The available methods are the same as for the
#'  `cluster_cut_method` configuration parameter: `silhouette`, `fixed_cut` and
#'  `dynamic_cut`.
#'
#'  `silhouette` is available for all cluster methods, but `fixed_cut` only
#'  applies to methods that create hierarchical trees (`hclust`, `agnes` and
#'  `diana`). `dynamic_cut` requires the `dynamicTreeCut` package and can only
#'  be used with `agnes` and `hclust`.
#'
#'  If not provided explicitly, this parameter is read from settings used at
#'  creation of the underlying `familiarModel` objects.
#'
#'@param feature_similarity_threshold The threshold level for pair-wise
#'  similarity that is required to form feature clusters with the `fixed_cut`
#'  method.
#'
#'  If not provided explicitly, this parameter is read from settings used at
#'  creation of the underlying `familiarModel` objects.
#'
#'@param feature_similarity_metric Metric to determine pairwise similarity
#'  between features. Similarity is computed in the same manner as for
#'  clustering, and `feature_similarity_metric` therefore has the same options
#'  as `cluster_similarity_metric`: `mcfadden_r2`, `cox_snell_r2`,
#'  `nagelkerke_r2`, `spearman`, `kendall` and `pearson`.
#'
#'  If not provided explicitly, this parameter is read from settings used at
#'  creation of the underlying `familiarModel` objects.
#'
#'@param sample_cluster_method The method used to perform clustering based on
#'  distance between samples. These are the same methods as for the
#'  `cluster_method` configuration parameter: `hclust`, `agnes`, `diana` and
#'  `pam`.
#'
#'  `none` cannot be used when extracting data for feature expressions.
#'
#'  If not provided explicitly, this parameter is read from settings used at
#'  creation of the underlying `familiarModel` objects.
#'
#'@param sample_linkage_method The method used for agglomerative clustering in
#'  `hclust` and `agnes`. These are the same methods as for the
#'  `cluster_linkage_method` configuration parameter: `average`, `single`,
#'  `complete`, `weighted`, and `ward`.
#'
#'  If not provided explicitly, this parameter is read from settings used at
#'  creation of the underlying `familiarModel` objects.
#'
#'@param sample_similarity_metric Metric to determine pairwise similarity
#'  between samples. Similarity is computed in the same manner as for
#'  clustering, but `sample_similarity_metric` has different options that are
#'  better suited to computing distance between samples instead of between
#'  features: `gower`, `euclidean`.
#'
#'  The underlying feature data is scaled to the \eqn{[0, 1]} range (for
#'  numerical features) using the feature values across the samples. The
#'  normalisation parameters required can optionally be computed from feature
#'  data with the outer 5% (on both sides) of feature values trimmed or
#'  winsorised. To do so append `_trim` (trimming) or `_winsor` (winsorising) to
#'  the metric name. This reduces the effect of outliers somewhat.
#'
#'  If not provided explicitly, this parameter is read from settings used at
#'  creation of the underlying `familiarModel` objects.
#'
#'@param icc_type String indicating the type of intraclass correlation
#'  coefficient (`1`, `2` or `3`) that should be used to compute robustness for
#'  features in repeated measurements during the evaluation of univariate
#'  importance. These types correspond to the types in Shrout and Fleiss (1979).
#'  If not provided explicitly, this parameter is read from settings used at
#'  creation of the underlying `familiarModel` objects.
#'@param verbose Flag to indicate whether feedback should be provided on the
#'  computation and extraction of various data elements.
#'@param message_indent Number of indentation steps for messages shown during
#'  computation and extraction of various data elements.
#'@param data_element String indicating which data elements are to be extracted.
#'  Default is `all`, but specific elements can be specified to speed up
#'  computations if not all elements are to be computed. This is an internal
#'  parameter that is set by, e.g. the `export_model_vimp` method.
#'@param ... Unused arguments.
#'
#'@inheritParams .parse_evaluation_settings
#'
#'@return A `familiarData` object.
#'@references 1. Shrout, P. E. & Fleiss, J. L. Intraclass correlations: uses in
#'  assessing rater reliability. Psychol. Bull. 86, 420–428 (1979).
#'@md
#'@keywords internal
setGeneric("extract_data", function(object,
                                    data,
                                    data_element=waiver(),
                                    is_pre_processed=FALSE,
                                    cl=NULL,
                                    time_max=waiver(),
                                    aggregation_method=waiver(),
                                    rank_threshold=waiver(),
                                    ensemble_method=waiver(),
                                    stratification_ensemble_method=waiver(),
                                    eval_times=waiver(),
                                    metric=waiver(),
                                    feature_cluster_method=waiver(),
                                    feature_cluster_cut_method=waiver(),
                                    feature_linkage_method=waiver(),
                                    feature_similarity_metric=waiver(),
                                    feature_similarity_threshold=waiver(),
                                    sample_cluster_method=waiver(),
                                    sample_linkage_method=waiver(),
                                    sample_similarity_metric=waiver(),
                                    detail_level=waiver(),
                                    estimation_type=waiver(),
                                    aggregate_results=waiver(),
                                    confidence_level=waiver(),
                                    bootstrap_ci_method=waiver(),
                                    compute_model_data=waiver(),
                                    compute_model_ci=waiver(),
                                    compute_ensemble_ci=waiver(),
                                    aggregate_ci=waiver(),
                                    icc_type=waiver(),
                                    dynamic_model_loading=FALSE,
                                    message_indent=0L,
                                    verbose=FALSE, ...) standardGeneric("extract_data"))

#####extract_data#####
setMethod("extract_data", signature(object="familiarEnsemble"),
          function(object,
                   data,
                   data_element=waiver(),
                   is_pre_processed=FALSE,
                   cl=NULL,
                   time_max=waiver(),
                   aggregation_method=waiver(),
                   rank_threshold=waiver(),
                   ensemble_method=waiver(),
                   stratification_ensemble_method=waiver(),
                   eval_times=waiver(),
                   metric=waiver(),
                   feature_cluster_method=waiver(),
                   feature_cluster_cut_method=waiver(),
                   feature_linkage_method=waiver(),
                   feature_similarity_metric=waiver(),
                   feature_similarity_threshold=waiver(),
                   sample_cluster_method=waiver(),
                   sample_linkage_method=waiver(),
                   sample_similarity_metric=waiver(),
                   detail_level=waiver(),
                   estimation_type=waiver(),
                   aggregate_results=waiver(),
                   confidence_level=waiver(),
                   bootstrap_ci_method=waiver(),
                   compute_model_data=waiver(),
                   compute_model_ci=waiver(),
                   compute_ensemble_ci=waiver(),
                   aggregate_ci=waiver(),
                   icc_type=waiver(),
                   dynamic_model_loading=FALSE,
                   message_indent=0L,
                   verbose=FALSE,
                   ...){
            # Generates a familiarData object from the ensemble.
            
            if(is.waive(data_element)) data_element <- .get_available_data_elements()
            
            # Check the data_element argument.
            if(length(data_element) > 0){
              .check_parameter_value_is_valid(x=data_element, var_name="data_element",
                                              values=.get_available_data_elements())
            }
            
            # Check the dynamic_model_loading argument because it is used here.
            .check_parameter_value_is_valid(x=dynamic_model_loading, var_name="dynamic_model_loading",
                                            values=c(FALSE, TRUE))
            
            # Set auto-detach here. Note that, if TRUE, load_models may reset it
            # to FALSE if models cannot be detached.
            object@auto_detach <- dynamic_model_loading
            
            # Check whether data is a dataObject, and create one otherwise.
            if(!is(data, "dataObject")){
              data <- as_data_object(data=data,
                                     object=object)
              
              # Set pre-processing level.
              data@preprocessing_level=ifelse(is_pre_processed, "clustering", "none")
            }
            
            # Load models, and drop any models that were not trained.
            object <- load_models(object=object, drop_untrained=TRUE)
            
            
            # Extract feature distance tables,
            if(any(c("mutual_correlation", "univariate_analysis", "feature_expressions", "permutation_vimp") %in% data_element)){
              # Not for the fs_vimp and model_vimp data elements. This is
              # because these derive cluster information from consensus
              # clustering.

              # Compute a table containg the pairwise distance between features.
              feature_similarity_table <- extract_feature_similarity_table(object=object,
                                                                           data=data,
                                                                           cl=cl,
                                                                           feature_similarity_metric=feature_similarity_metric,
                                                                           message_indent=message_indent,
                                                                           verbose=verbose)
            }

            if(any(c("feature_expressions") %in% data_element)){
              # Compute a table containing the pairwise distance between samples.
              sample_similarity_table <- extract_sample_similarity_table(object=object,
                                                                         data=data,
                                                                         cl=cl,
                                                                         sample_similarity_metric=sample_similarity_metric,
                                                                         message_indent=message_indent,
                                                                         verbose=verbose)
            }

            # Extract feature variable importance
            if(any(c("fs_vimp") %in% data_element)){
              fs_vimp_info <- extract_fs_vimp(object=object,
                                              aggregation_method=aggregation_method,
                                              rank_threshold=rank_threshold,
                                              message_indent=message_indent,
                                              verbose=verbose)
            } else {
              fs_vimp_info <- NULL
            }


            # Extract model-based variable importance
            if(any(c("model_vimp") %in% data_element)){
              model_vimp_info <- extract_model_vimp(object=object,
                                                    aggregation_method=aggregation_method,
                                                    rank_threshold=rank_threshold,
                                                    message_indent=message_indent,
                                                    verbose=verbose)
            } else {
              model_vimp_info <- NULL
            }
            
            
            # Assess permutation variable importance
            if(any(c("permutation_vimp") %in% data_element)){
              permutation_vimp <- extract_permutation_vimp(object=object,
                                                           data=data,
                                                           cl=cl,
                                                           feature_similarity_table=feature_similarity_table,
                                                           feature_cluster_method=feature_cluster_method,
                                                           feature_linkage_method=feature_linkage_method,
                                                           feature_cluster_cut_method=feature_cluster_cut_method,
                                                           feature_similarity_metric=feature_similarity_metric,
                                                           feature_similarity_threshold=feature_similarity_threshold,
                                                           metric=metric,
                                                           ensemble_method=ensemble_method,
                                                           eval_times=eval_times,
                                                           detail_level=detail_level,
                                                           estimation_type=estimation_type,
                                                           aggregate_results=aggregate_results,
                                                           confidence_level=confidence_level,
                                                           bootstrap_ci_method=bootstrap_ci_method,
                                                           message_indent=message_indent,
                                                           verbose=verbose)
            } else {
              permutation_vimp <- NULL
            }
            
            
            # Create mutual correlation information
            if(any(c("mutual_correlation") %in% data_element)){
              mutual_corr_info <- extract_mutual_correlation(object=object,
                                                             data=data,
                                                             feature_similarity_table=feature_similarity_table,
                                                             feature_cluster_method=feature_cluster_method,
                                                             feature_linkage_method=feature_linkage_method,
                                                             feature_similarity_metric=feature_similarity_metric,
                                                             message_indent=message_indent,
                                                             verbose=verbose)
            } else {
              mutual_corr_info <- NULL
            }

            # Expression heatmap data
            if(any(c("feature_expressions") %in% data_element)){
              expression_info <- extract_feature_expression(object=object,
                                                            data=data,
                                                            feature_similarity_table,
                                                            sample_similarity_table,
                                                            feature_cluster_method=feature_cluster_method,
                                                            feature_linkage_method=feature_linkage_method,
                                                            feature_similarity_metric=feature_similarity_metric,
                                                            sample_cluster_method=sample_cluster_method,
                                                            sample_linkage_method=sample_linkage_method,
                                                            sample_similarity_metric=sample_similarity_metric,
                                                            eval_times=eval_times,
                                                            message_indent=message_indent,
                                                            verbose=verbose)
            } else {
              expression_info <- NULL
            }


            # Univariate analysis
            if(any(c("univariate_analysis") %in% data_element)){
              univar_info <- extract_univariate_analysis(object=object,
                                                         data=data,
                                                         cl=cl,
                                                         icc_type=icc_type,
                                                         feature_similarity_table=feature_similarity_table,
                                                         feature_cluster_method=feature_cluster_method,
                                                         feature_cluster_cut_method=feature_cluster_cut_method,
                                                         feature_linkage_method=feature_linkage_method,
                                                         feature_similarity_threshold=feature_similarity_threshold,
                                                         feature_similarity_metric=feature_similarity_metric,
                                                         message_indent=message_indent,
                                                         verbose=verbose)
            } else {
              univar_info <- NULL
            }


            # Extract hyper-parameters
            if(any(c("hyperparameters") %in% data_element)){
              hyperparameter_info <- extract_hyperparameters(object=object,
                                                             message_indent=message_indent,
                                                             verbose=verbose)
            } else {
              hyperparameter_info <- NULL
            }
            
            
            # Create predictions.
            if(any(c("prediction_data") %in% data_element)){
              prediction_data <- extract_predictions(object=object,
                                                     data=data,
                                                     cl=cl,
                                                     ensemble_method=ensemble_method,
                                                     detail_level=detail_level,
                                                     estimation_type=estimation_type,
                                                     aggregate_results=aggregate_results,
                                                     confidence_level=confidence_level,
                                                     eval_times=eval_times,
                                                     message_indent=message_indent,
                                                     verbose=verbose)
            } else {
              prediction_data <- NULL
            }
            
            # Compute model performance based on the prediction_data
            if(any(c("model_performance") %in% data_element)){
              model_performance_data <- extract_performance(object=object,
                                                            data=data,
                                                            cl=cl,
                                                            metric=metric,
                                                            ensemble_method=ensemble_method,
                                                            eval_times=eval_times,
                                                            detail_level=detail_level,
                                                            estimation_type=estimation_type,
                                                            aggregate_results=aggregate_results,
                                                            confidence_level=confidence_level,
                                                            bootstrap_ci_method=bootstrap_ci_method,
                                                            message_indent=message_indent,
                                                            verbose=verbose)
              
            } else {
              model_performance_data <- NULL
            }
            
            # Compute the decision curve analysis data.
            if(any(c("decision_curve_analyis") %in% data_element)){
              decision_curve_data <- extract_decision_curve_data(object=object,
                                                                 data=data,
                                                                 cl=cl,
                                                                 ensemble_method=ensemble_method,
                                                                 eval_times=eval_times,
                                                                 confidence_level=confidence_level,
                                                                 bootstrap_ci_method=bootstrap_ci_method,
                                                                 compute_model_data=compute_model_data,
                                                                 compute_model_ci=compute_model_ci,
                                                                 compute_ensemble_ci=compute_ensemble_ci,
                                                                 aggregate_ci=aggregate_ci,
                                                                 message_indent=message_indent,
                                                                 verbose=verbose)
              
            } else {
              decision_curve_data <- NULL
            }
            
            
            # Extract information regarding stratification
            if(any(c("stratification_data") %in% data_element)){
              km_info <- extract_km_cutoffs(object=object,
                                            message_indent=message_indent,
                                            verbose=verbose)
            } else {
              km_info <- NULL
            }
            
            
            # Compute stratification tests
            if(any(c("kaplan_meier_data") %in% data_element)){
              stratification_data <- extract_stratification_data(object=object,
                                                                 data=data,
                                                                 ensemble_method=ensemble_method,
                                                                 stratification_ensemble_method=stratification_ensemble_method,
                                                                 time_max=time_max,
                                                                 message_indent=message_indent,
                                                                 verbose=verbose)
              
            } else {
              stratification_data <- NULL
            }
            
            # Extract calibration data
            if(any(c("calibration_data") %in% data_element)){
              calibration_data <- extract_calibration_data(object=object,
                                                           data=data,
                                                           eval_times=eval_times,
                                                           message_indent=message_indent,
                                                           verbose=verbose)
            } else {
              calibration_data <- NULL
            }
            
            # Extract AUC data
            if(any(c("auc_data") %in% data_element)){
              auc_data <- extract_auc_data(object=object,
                                           data=data,
                                           cl=cl,
                                           ensemble_method=ensemble_method,
                                           detail_level=detail_level,
                                           estimation_type=estimation_type,
                                           aggregate_results=aggregate_results,
                                           bootstrap_ci_method=bootstrap_ci_method,
                                           confidence_level=confidence_level,
                                           message_indent=message_indent,
                                           verbose=verbose)
            } else {
              auc_data <- NULL
            }
            
            # Extract confusion matrix data.
            if(any(c("confusion_matrix") %in% data_element)){
              confusion_matrix_info <- extract_confusion_matrix(object=object,
                                                                data=data,
                                                                cl=cl,
                                                                ensemble_method=ensemble_method,
                                                                detail_level=detail_level,
                                                                message_indent=message_indent,
                                                                verbose=verbose)
            } else {
              confusion_matrix_info <- NULL
            }

            # Set up a placehold pooling table. This may need to be adepted.
            pooling_table <- data.table::data.table("ensemble_data_id"=object@run_table$ensemble_data_id,
                                                    "ensemble_run_id"=object@run_table$ensemble_run_id,
                                                    "data_perturb_level"=ifelse(is.na(data@perturb_level), 0, data@perturb_level),
                                                    "pool_data_id"=0L,
                                                    "pool_run_id"=0,
                                                    "pool_perturb_level"=0)
            
            # Create a familiarData object
            fam_data <- methods::new("familiarData",
                                     outcome_type = object@outcome_type,
                                     outcome_info = object@outcome_info,
                                     fs_vimp = fs_vimp_info,
                                     model_vimp = model_vimp_info,
                                     permutation_vimp = permutation_vimp,
                                     hyperparameters = hyperparameter_info,
                                     hyperparameter_data = NULL,
                                     required_features = object@required_features,
                                     model_features = object@model_features,
                                     learner = object@learner,
                                     fs_method = object@fs_method,
                                     pooling_table = pooling_table,
                                     prediction_data = prediction_data,
                                     confusion_matrix = confusion_matrix_info,
                                     decision_curve_data = decision_curve_data,
                                     calibration_info = add_model_name(object@calibration_info, object=object),
                                     calibration_data = calibration_data,
                                     model_performance = model_performance_data,
                                     km_info = km_info,
                                     km_data = stratification_data,
                                     auc_data = auc_data,
                                     univariate_analysis = univar_info,
                                     feature_expressions = expression_info,
                                     mutual_correlation = mutual_corr_info,
                                     ice_data = NULL,
                                     is_anonymised = FALSE,
                                     is_validation = data@load_validation,
                                     generating_ensemble = get_object_name(object=object, abbreviated=FALSE),
                                     project_id = object@project_id)
            
            # Add package version to the data set 
            fam_data <- add_package_version(object=fam_data)
            
            # Return data
            return(fam_data)
          })

#'@title Internal function to extract feature selection variable importance.
#'
#'@description Aggregate variable importance obtained during feature selection.
#'  This information can only be obtained as part of the main `summon_familiar` process.
#'
#'@inheritParams extract_data
#'
#'@return A list containing feature selection variable importance information.
#'@md
#'@keywords internal
setGeneric("extract_fs_vimp", function(object,
                                       aggregation_method=waiver(),
                                       rank_threshold=waiver(),
                                       message_indent=0L,
                                       verbose=FALSE,
                                       ...) standardGeneric("extract_fs_vimp"))

#####extract_fs_vimp#####
setMethod("extract_fs_vimp", signature(object="familiarEnsemble"),
          function(object,
                   aggregation_method=waiver(),
                   rank_threshold=waiver(),
                   message_indent=0L,
                   verbose=FALSE){
            
            # Obtain aggregation method from stored settings, if required.
            if(is.waive(aggregation_method)){
              aggregation_method <- object@settings$aggregation
            }
            
            # Check aggregation method
            rank.check_aggregation_method(method=aggregation_method)
            
            # Obtain rank thresholds from stored settings, if required
            if(is.waive(rank_threshold)){
              rank_threshold <- object@settings$aggr_rank_threshold
            }
            
            # Check rank threshold. NULL is an allowed value.
            if(!is.null(rank_threshold)){
              .check_number_in_valid_range(x=rank_threshold, var_name="rank_threshold", range=c(1, Inf))
            }
            
            # Load project list and file_paths
            file_paths <- tryCatch({get_file_paths()}, error=function(err)(return(NULL)))
            project_list <- tryCatch({get_project_list()}, error=function(err)(return(NULL)))
            
            if(is.null(file_paths) | is.null(project_list)){
              return(list("vimp_table" = NULL,
                          "aggregation_method" = aggregation_method,
                          "rank_threshold" = rank_threshold))
            }
            
            # Message extraction start
            if(verbose){
              logger.message(paste0("Extracting variable importance obtained during feature selection."),
                             indent=message_indent)
            }
            
            # Define the run table -> at the pooling level
            run <- .get_run_list(iteration_list=project_list$iter_list,
                                 data_id=object@run_table$ensemble_data_id,
                                 run_id=object@run_table$ensemble_run_id)
            
            # Obtain variable importance table
            vimp_table <- rank.get_vimp_table(run=run,
                                              fs_method=object@fs_method,
                                              proj_list=project_list,
                                              file_paths=file_paths,
                                              decluster=TRUE)
            
            # Find the translation_table by performing consensus clustering.
            translation_table <- rank.consensus_clustering(vimp_table=vimp_table)
            
            # Extract variable importance information
            fs_vimp <- rank.get_feature_ranks(vimp_table=vimp_table,
                                              translation_table=translation_table,
                                              aggregation_method=aggregation_method,
                                              rank_threshold=rank_threshold,
                                              decluster=TRUE)
            
            # Extract feature occurrence within top 5.
            occurrence_vimp <- rank.get_feature_ranks(vimp_table=vimp_table,
                                                      translation_table=translation_table,
                                                      aggregation_method="stability",
                                                      rank_threshold=5,
                                                      decluster=TRUE)
            
            # Remove the aggr_rank and cluster_id column and rename the aggr_score column.
            occurrence_vimp[, ":="("aggr_rank"=NULL, "cluster_id"=NULL)]
            data.table::setnames(occurrence_vimp, "aggr_score", "occurrence")
            
            # Merge occurrence into the main variable importance table based on feature name.
            if(is_empty(occurrence_vimp)){
              fs_vimp[, "occurrence":=numeric(0)]
            } else {
              fs_vimp <- merge(x=fs_vimp, y=occurrence_vimp, on="name", all=TRUE)
            }
            
            # Update names
            data.table::setnames(fs_vimp, c("aggr_rank", "aggr_score"), c("rank", "score"))
            fs_vimp <- fs_vimp[order(rank)]
            
            # Add cluster size.
            fs_vimp[, "cluster_size":=.N, by="cluster_id"]
            
            # Set column order
            data.table::setcolorder(fs_vimp, neworder=c("name", "score", "rank", "occurrence", "cluster_id", "cluster_size"))
            
            # Store vimp information with settings used to determine the ranks
            vimp_info <- list("vimp_table" = fs_vimp,
                              "aggregation_method" = aggregation_method,
                              "rank_threshold" = rank_threshold)
            
            return(vimp_info)
          })



#'@title Internal function to extract variable importance from models.
#'
#'@description Aggregate variable importance from models in a
#'  `familiarEnsemble`.
#'
#'@param feature_similarity_table Table containing pairwise distance between
#'  features. This is used to determine cluster information, and indicate
#'  co-clustered important features. The table is created by the
#'  `extract_feature_similarity_table` method.
#'@inheritParams extract_data
#'
#'@return A list containing variable importance information.
#'@md
#'@keywords internal
setGeneric("extract_model_vimp", function(object,
                                          aggregation_method=waiver(),
                                          rank_threshold=waiver(),
                                          message_indent=0L,
                                          verbose=FALSE,
                                          ...) standardGeneric("extract_model_vimp"))

#####extract_model_vimp (familiarEnsemble)#####
setMethod("extract_model_vimp", signature(object="familiarEnsemble"),
          function(object,
                   aggregation_method=waiver(),
                   rank_threshold=waiver(),
                   message_indent=0L,
                   verbose=FALSE,
                   ...){
            
            # Message extraction start
            if(verbose){
              logger.message(paste0("Extracting variable importance obtained from the models."),
                             indent=message_indent)
            }
            
            # Test if models are properly loaded
            if(!is_model_loaded(object=object)) ..error_ensemble_models_not_loaded()
            
            # Obtain aggregation method from stored settings, if required.
            if(is.waive(aggregation_method)) aggregation_method <- object@settings$aggregation
            
            # Check aggregation method
            rank.check_aggregation_method(method=aggregation_method)
            
            # Obtain rank thresholds from stored settings, if required
            if(is.waive(rank_threshold)) rank_threshold <- object@settings$aggr_rank_threshold
            
            # Check rank threshold. NULL is an allowed value.
            if(!is.null(rank_threshold)){
              .check_number_in_valid_range(x=rank_threshold, var_name="rank_threshold", range=c(1, Inf))
            }
            
            # Suppress NOTES due to non-standard evaluation in data.table
            rank <- NULL
            
            # Check that any model has been successfully trained.
            if(!model_is_trained(object)){
              return(list("vimp_table" = NULL,
                          "aggregation_method" = aggregation_method,
                          "rank_threshold" = rank_threshold))
            }
            
            # Get variable importance from individual models
            raw_model_vimp <- data.table::rbindlist(lapply(object@model_list, extract_model_vimp))
            
            # Check for empty model_vimp
            if(is_empty(raw_model_vimp)){
              return(list("vimp_table" = NULL,
                          "aggregation_method" = aggregation_method,
                          "rank_threshold" = rank_threshold))
            }
            
            
            # Find translation table.
            translation_table <- rank.consensus_clustering(vimp_table=raw_model_vimp)
            
            # Re-cluster variables so that each cluster of features will only be counted
            # once. This is particularly helpful for features that incorporate
            # occurrence or use a threshold for the important set of features.
            raw_model_vimp <- rank.recluster_vimp_table(vimp_table=raw_model_vimp,
                                                        translation_table=translation_table)
            
            # Determine aggregate ranks
            model_vimp <- rank.aggregate_feature_ranks(dt_vimp=raw_model_vimp,
                                                       aggregation_method=aggregation_method,
                                                       rank_threshold=rank_threshold)
            
            # Extract feature occurrence within top 5.
            occurrence_vimp <- rank.aggregate_feature_ranks(dt_vimp=raw_model_vimp,
                                                            aggregation_method="stability",
                                                            rank_threshold=5)
            
            # Remove the aggr_rank column and rename the aggr_score column.
            occurrence_vimp[, ":="("aggr_rank"=NULL)]
            data.table::setnames(occurrence_vimp, "aggr_score", "occurrence")
            
            # Merge occurrence into the main variable importance table based on feature name.
            if(is_empty(occurrence_vimp)){
              model_vimp[, "occurrence":=numeric(0)]
            } else {
              model_vimp <- merge(x=model_vimp, y=occurrence_vimp, on="name", all=TRUE)
            }
            
            # Replace clusters by individual features
            model_vimp <- rank.decluster_vimp_table(vimp_table=model_vimp,
                                                    translation_table=translation_table)
            
            # Update column names
            data.table::setnames(model_vimp, c("aggr_rank", "aggr_score"), c("rank", "score"))
            model_vimp <- model_vimp[order(rank)]
            
            # Add cluster size.
            model_vimp[, "cluster_size":=.N, by="cluster_id"]

            # Store vimp information with settings used to determine the ranks
            vimp_info <- list("vimp_table" = model_vimp,
                              "aggregation_method" = aggregation_method,
                              "rank_threshold" = rank_threshold)
            
            # Return variable importance information
            return(vimp_info)
          })

#####extract_model_vimp (familiarModel)#####
setMethod("extract_model_vimp", signature(object="familiarModel"),
          function(object, ...){
            
            # Extract variable importance from the models
            model_vimp <- ..vimp(object)
            
            # Add the data_id and run_id column
            model_vimp[, ":="("data_id"=tail(object@run_table, n=1)$data_id,
                              "run_id"=tail(object@run_table, n=1)$run_id)]
            
            # Decluster data
            model_vimp <- rank.decluster_vimp_table(vimp_table=model_vimp,
                                                    feature_info_list=object@feature_info)
            
            return(model_vimp)
          })

#####extract_model_vimp (character)######
setMethod("extract_model_vimp", signature(object="character"),
          function(object, ...){
            # Load object.
            object <- load_familiar_object(object)
            
            return(do.call(extract_model_vimp, args=c(list("object"=object),
                                                      list(...))))
          })



#'@title Internal function to extract hyperparameters from models.
#'
#'@description Collects hyperparameters from models in a `familiarEnsemble`.
#'
#'@inheritParams extract_data
#'
#'@return A `data.table` with hyperparameters.
#'@md
#'@keywords internal
setGeneric("extract_hyperparameters", function(object,
                                               message_indent=0L,
                                               verbose=FALSE,
                                               ...) standardGeneric("extract_hyperparameters"))

#####extract_hyperparameters (familiarEnsemble)#####
setMethod("extract_hyperparameters", signature(object="familiarEnsemble"),
          function(object,
                   message_indent=0L,
                   verbose=FALSE){
            # Extracts hyper-parameters from each model and collects them.
            
            # Message extraction start
            if(verbose){
              logger.message(paste0("Extracting hyperparameters from the models in the ensemble."),
                             indent=message_indent)
            }
            
            # Test if models are properly loaded
            if(!is_model_loaded(object=object)) ..error_ensemble_models_not_loaded()
            
            # Test if the any of the models in the ensemble were trained.
            if(!model_is_trained(object)) return(NULL)
            
            # Collect hyperparameters
            hyperparameter_info <- data.table::rbindlist(lapply(object@model_list, extract_hyperparameters))
            
            return(hyperparameter_info)
          })

#####extract_hyperparameters (familiarModel)#####
setMethod("extract_hyperparameters", signature(object="familiarModel"),
          function(object, ...){
            # Parse hyperparameters as data.table
            data <- data.table::as.data.table(object@hyperparameters)
            
            # Add model name column
            data <- add_model_name(data=data,
                                   object=object)
            
            return(data)
          })

#####extract_hyperparameters (character)#####
setMethod("extract_hyperparameters", signature(object="character"),
          function(object, ...){
            # Load object.
            object <- load_familiar_object(object)
            
            return(do.call(extract_hyperparameters, args=list("object"=object)))
          })


#'@title Internal function to extract Kaplan-Meier risk group stratification cutoffs from models.
#'
#'@description Collects Kaplan-Meier risk group stratification cutoffs from
#'  models in a `familiarEnsemble`.
#'
#'@inheritParams extract_data
#'
#'@return A data.table with risk group cutoffs.
#'@md
#'@keywords internal
setGeneric("extract_km_cutoffs", function(object,
                                          message_indent=0L,
                                          verbose=FALSE,
                                          ...) standardGeneric("extract_km_cutoffs"))

#####extract_km_cutoffs (familiarEnsemble)#####
setMethod("extract_km_cutoffs", signature(object="familiarEnsemble"),
          function(object,
                   message_indent=0L,
                   verbose=FALSE){
            
            # Test if the outcome type is survival
            if(!object@outcome_type %in% c("survival")) return(NULL)
            
            # Message extraction start
            if(verbose){
              logger.message(paste0("Extracting Kaplan-Meier cutoffs from the models."),
                             indent=message_indent)
            }
            
            # Test if models are properly loaded
            if(!is_model_loaded(object=object)) ..error_ensemble_models_not_loaded()
            
            # Test if any model in the ensemble was successfully trained.
            if(!model_is_trained(object=object)) return(NULL)
            
            # Collect Kaplan-Meier stratification parameters
            km_cut_off_info <- data.table::rbindlist(lapply(object@model_list, extract_km_cutoffs))
            
            return(km_cut_off_info)
          })

#####extract_km_cutoffs (familiarModel)#####
setMethod("extract_km_cutoffs", signature(object="familiarModel"),
          function(object, ...){
            
            if(is_empty(object@km_info$parameters)) return(NULL)
            
            # Iterate over stratification parameters
            data <- data.table::rbindlist(lapply(object@km_info$parameters, function(method_list){
              
              # Extract information
              data <- data.table::data.table("stratification_method"=method_list$method,
                                             "cutoff"=method_list$cutoff,
                                             "index"=seq_len(length(method_list$cutoff)))
              
              return(data)
            }))
            
            # Add model name column
            data <- add_model_name(data=data, object=object)
            
            return(data)
          })

#####extract_km_cutoffs (character)#####
setMethod("extract_km_cutoffs", signature(object="character"),
          function(object, ...){
            # Load object.
            object <- load_familiar_object(object)
            
            return(do.call(extract_km_cutoffs, args=list("object"=object)))
          })


#'@title Internal function to extract calibration data.
#'
#'@description Computes calibration data from a `familiarEnsemble` object.
#'  Calibration tests are performed based on expected (predicted) and observed
#'  outcomes. For all outcomes, calibration-at-the-large and calibration slopes
#'  are determined. Furthermore, for all but survival outcomes, a repeated,
#'  randomised grouping Hosmer-Lemeshow test is performed. For survival
#'  outcomes, the Nam-D'Agostino and Greenwood-Nam-D'Agostino tests are
#'  performed.
#'
#'@inheritParams extract_data
#'
#'@return A list with data.tables containing calibration test information for
#'  the ensemble model.
#'@md
#'@keywords internal
setGeneric("extract_calibration_data",
           function(object,
                    data,
                    eval_times=waiver(),
                    is_pre_processed=FALSE,
                    message_indent=0L,
                    verbose=FALSE,
                    ...) standardGeneric("extract_calibration_data"))

#####extract_calibration_data#####
setMethod("extract_calibration_data", signature(object="familiarEnsemble"),
          function(object,
                   data,
                   eval_times=waiver(),
                   is_pre_processed=FALSE,
                   message_indent=0L,
                   verbose=FALSE,
                   ...){
            
            # Message extraction start
            if(verbose){
              logger.message(paste0("Assessing model calibration."),
                             indent=message_indent)
            }
            
            # Load eval_times from the object settings attribute, if it is not provided.
            if(is.waive(eval_times)){
              eval_times <- object@settings$eval_times
            }
            
            # Check eval_times argument
            if(object@outcome_type %in% c("survival")){
              sapply(eval_times, .check_number_in_valid_range, var_name="eval_times", range=c(0.0, Inf), closed=c(FALSE, TRUE))
            }
            
            # Test if models are properly loaded
            if(!is_model_loaded(object=object)) ..error_ensemble_models_not_loaded()

            # Test if any model in the ensemble was successfully trained.
            if(!model_is_trained(object=object)) return(NULL)
            
            # This function is the same for familiarModel and familiarEnsemble objects
            return(assess_calibration(object=object, data=data, eval_times=eval_times, is_pre_processed=is_pre_processed))
          })


#'@title Internal function to extract stratification data.
#'
#'@description Computes and extracts stratification data from a
#'  `familiarEnsemble` object. This includes the data required to draw
#'  Kaplan-Meier plots, as well as logrank and hazard-ratio tests between the
#'  respective risk groups.
#'
#'@inheritParams extract_data
#'
#'@return A list with data.tables containing information concerning risk group
#'  stratification.
#'@md
#'@keywords internal
setGeneric("extract_stratification_data", function(object,
                                                   data=NULL,
                                                   ensemble_method=waiver(),
                                                   time_max=waiver(),
                                                   risk_group_list=NULL,
                                                   stratification_ensemble_method=waiver(),
                                                   message_indent=0L,
                                                   verbose=FALSE,
                                                   ...) standardGeneric("extract_stratification_data"))
#####extract_stratification_data#####
setMethod("extract_stratification_data", signature(object="familiarEnsemble"),
          function(object,
                   data=NULL,
                   ensemble_method=waiver(),
                   time_max=waiver(),
                   risk_group_list=NULL,
                   stratification_ensemble_method=waiver(),
                   message_indent=0L,
                   verbose=FALSE,
                   ...){
            
            # Only assess stratification for survival outcomes.
            if(!object@outcome_type %in% c("survival")) return(NULL)
            
            # Message extraction start
            if(verbose){
              logger.message(paste0("Assessing stratification into risk groups."),
                             indent=message_indent)
            }
            
            # Assess stratification
            return(assess_stratification(object=object,
                                         data=data,
                                         ensemble_method=ensemble_method,
                                         time_max=time_max,
                                         risk_group_list=risk_group_list,
                                         stratification_ensemble_method=stratification_ensemble_method))
          })


#'@title Internal function to extract data from a univariate analysis.
#'
#'@description Computes and extracts univariate analysis for the features used
#'  in a `familiarEnsemble` object. This assessment includes the computation of
#'  p and q-values, as well as robustness (in case of repeated measurements).
#'
#'@inheritParams extract_data
#'
#'@return A list with a data.table containing information concerning the
#'  univariate analysis of important features.
#'@md
#'@keywords internal
setGeneric("extract_univariate_analysis", function(object,
                                                   data,
                                                   cl=NULL,
                                                   icc_type=waiver(),
                                                   feature_similarity_table=NULL,
                                                   feature_cluster_method=waiver(),
                                                   feature_cluster_cut_method=waiver(),
                                                   feature_linkage_method=waiver(),
                                                   feature_similarity_threshold=waiver(),
                                                   feature_similarity_metric=waiver(),
                                                   message_indent=0L,
                                                   verbose=FALSE,
                                                   ...) standardGeneric("extract_univariate_analysis"))

#####extract_univariate_analysis#####
setMethod("extract_univariate_analysis", signature(object="familiarEnsemble", data="ANY"),
          function(object,
                   data,
                   cl=NULL,
                   icc_type=waiver(),
                   feature_similarity_table=NULL,
                   feature_cluster_method=waiver(),
                   feature_cluster_cut_method=waiver(),
                   feature_linkage_method=waiver(),
                   feature_similarity_threshold=waiver(),
                   feature_similarity_metric=waiver(),
                   message_indent=0L,
                   verbose=FALSE){
            
            # Message extraction start
            if(verbose){
              logger.message(paste0("Extracting univariate analysis information."),
                             indent=message_indent)
            }
            
            # Obtain cluster method from stored settings, if required.
            if(is.waive(feature_cluster_method)){
              feature_cluster_method <- object@settings$feature_cluster_method
            }
            
            # Obtain linkage function from stored settings, if required.
            if(is.waive(feature_linkage_method)){
              feature_linkage_method <- object@settings$feature_linkage_method
            }
            
            # Obtain feature cluster cut method from stored settings, if
            # required.
            if(is.waive(feature_cluster_cut_method)){
              feature_cluster_cut_method <- object@settings$feature_cluster_cut_method
            }
            
            # Obtain cluster similarity threshold from stored settings, if
            # required.
            if(is.waive(feature_similarity_threshold)){
              feature_similarity_threshold <- object@settings$feature_similarity_threshold
            }
            
            # Obtain similarity metric from stored settings, if required.
            if(is.waive(feature_similarity_metric)){
              feature_similarity_metric <- object@settings$feature_similarity_metric
            }
            
            # Replace feature cluster method == "none" with "hclust"
            if(feature_cluster_method == "none"){
              feature_cluster_method <- "hclust"
            }
            
            .check_cluster_parameters(cluster_method=feature_cluster_method,
                                      cluster_linkage=feature_linkage_method,
                                      cluster_cut_method=feature_cluster_cut_method,
                                      cluster_similarity_threshold=feature_similarity_threshold,
                                      cluster_similarity_metric=feature_similarity_metric,
                                      var_type="feature")
            
            # Suppress NOTES due to non-standard evaluation in data.table
            p_value <- NULL
            
            # Get and process the input data
            data <- process_input_data(object=object, data=data, stop_at="normalisation")
            
            # Determine some of the processing settings
            if(!all(data@data$repetition_id==1)){
              is_repeated_measurement <- TRUE
              
              # Obtain from settings, if unset.
              if(is.waive(icc_type)){
                icc_type <- object@settings$icc_type
              }
              
              # Check icc_type
              .check_parameter_value_is_valid(x=icc_type, var_name="icc_type",
                                              values=.get_available_icc_types())
            } else {
              is_repeated_measurement <- FALSE
            }
            
            has_qvalue_package <- is_package_installed(name="qvalue", verbose=FALSE)
            
            # Check if the data object is empty -- return an empty table if this
            # is the case.
            if(is_empty(data)) return(NULL)
            
            # Check if the number of samples is sufficient (>5), and return an
            # empty table if not.
            if(data.table::uniqueN(data@data, by=get_id_columns(id_depth="sample")) <= 5) return(NULL)
            
            # Maintain only important features. The current set is based on the
            # required features.
            data <- filter_features(data=data,
                                    available_features=object@model_features)
            
            # Determine feature columns
            feature_columns <- get_feature_columns(x=data)
            
            # Check if there are any features in the model.
            if(length(feature_columns) == 0) return(NULL)
            
            # Calculate univariate P values, based on aggregated data
            regr_p_values <- compute_univariable_p_values(cl=cl,
                                                          data_obj=aggregate_data(data=data),
                                                          feature_columns=feature_columns)
            
            # Find and replace non-finite values
            regr_p_values[!is.finite(regr_p_values)] <- 1.0
            
            # Collect to table
            univariate_data <- data.table::data.table("name"=names(regr_p_values),
                                                      "p_value"=regr_p_values)[order(p_value)]
            univariate_data[, "p_value_corrected":=stats::p.adjust(p_value, method="fdr")]
            
            # Only introduce q-values if the qvalue package is installed
            if(has_qvalue_package){
              
              # q-values can only be computed for larger numbers of features
              computed_q_value <- tryCatch({
                qvalue::qvalue(p=univariate_data$p_value)$qvalues
              }, error=function(err){
                return(NA_real_)
              })
              
              # Set q-value
              univariate_data[, "q_value":=computed_q_value]
            }
            
            # Determine whether robustness data can be added Check if repeated
            # measurements are present, otherwise return no feature names.
            if(is_repeated_measurement){
              
              # Determine which columns actually contains numeric data
              numeric_columns <- feature_columns[sapply(feature_columns, function(ii, data) (is.numeric(data@data[[ii]])), data=data)]
              
              if(length(numeric_columns) == 0){
                # If there are no numeric columns, add empty ICC data columns.
                univariate_data <- cbind(univariate_data,
                                         data.table::data.table("icc"=NA_real_,
                                                                "icc_low"=NA_real_,
                                                                "icc_up"=NA_real_,
                                                                "icc_panel"=NA_real_,
                                                                "icc_panel_low"=NA_real_,
                                                                "icc_panel_up"=NA_real_))
                
              } else {
                # Compute ICC values
                icc_list <- fam_mapply(cl=cl,
                                       assign=NULL,
                                       FUN=compute_icc,
                                       x=data@data[, mget(numeric_columns)],
                                       feature=numeric_columns,
                                       progress_bar=FALSE,
                                       MoreArgs=list("id_data"=data@data[, mget(get_id_columns(id_depth="repetition"))],
                                                     "type"=icc_type))
                
                # Merge with univariate_data
                univariate_data <- merge(x=univariate_data, y=data.table::rbindlist(icc_list), by="name", all.x=TRUE)
              }
            }
            
            # Find cluster info
            if(!is_empty(feature_similarity_table)){
              
              # Compute the distance matrix
              distance_matrix <- cluster.get_distance_matrix(similarity_table=feature_similarity_table,
                                                             similarity_metric=feature_similarity_metric)
              
              # TODO: update so that this works for multiple similarity thresholds.
              if(length(feature_similarity_threshold) > 0) feature_similarity_threshold <- feature_similarity_threshold[1]
              
              # Find cluster information
              cluster_info <- cluster.get_cluster_table(distance_matrix=distance_matrix,
                                                        require_representation=FALSE,
                                                        cluster_method=feature_cluster_method,
                                                        cluster_linkage=feature_linkage_method,
                                                        cluster_cut_method=feature_cluster_cut_method,
                                                        cluster_similarity_threshold=feature_similarity_threshold,
                                                        cluster_similarity_metric=feature_similarity_metric)
              
              # Keep only name and cluster_id columns
              cluster_info <- cluster_info[, c("name", "cluster_id"), with=FALSE]
              
              # Compute cluster size
              cluster_info[, "cluster_size":=.N, by="cluster_id"]
              
              # Merge into model_vimp
              univariate_data <- merge(univariate_data, cluster_info, by="name")
              
            } else {
              # Add singular clusters
              univariate_data[, ":="("cluster_id"=.I, "cluster_size"=1L)]
            }
            
            # Add model name
            univariate_data <- add_model_name(data=univariate_data, object=object)
            
            # Package to list
            univariate_info <- list("data"=univariate_data)
            
            # Add ICC type if it is used.
            if(is_repeated_measurement) univariate_info$icc_type <- icc_type

            return(univariate_info)
          })


#'@title Internal function to extract mutual correlation data.
#'
#'@description Computes and extracts pairwise correlation between the features
#'  used in a `familiarEnsemble` object.
#'
#'@inheritParams extract_data
#'
#'@return A list with a data.table containing mutual correlation between
#'  features.
#'@md
#'@keywords internal
setGeneric("extract_mutual_correlation", function(object,
                                                  data,
                                                  feature_cluster_method=waiver(),
                                                  feature_linkage_method=waiver(),
                                                  feature_similarity_metric=waiver(),
                                                  message_indent=0L,
                                                  verbose=FALSE,
                                                  ...) standardGeneric("extract_mutual_correlation"))


#####extract_mutual_correlation#####
setMethod("extract_mutual_correlation", signature(object="familiarEnsemble", data="ANY"),
          function(object,
                   data,
                   feature_similarity_table,
                   feature_cluster_method=waiver(),
                   feature_linkage_method=waiver(),
                   feature_similarity_metric=waiver(),
                   message_indent=0L,
                   verbose=FALSE){
            # Assess mutual correlation
            
            # Message extraction start
            if(verbose){
              logger.message(paste0("Computing similarity between important features."),
                             indent=message_indent)
            }

            # Obtain cluster method from stored settings, if required.
            if(is.waive(feature_cluster_method)){
              feature_cluster_method <- object@settings$feature_cluster_method
            }
            
            # Obtain linkage function from stored settings, if required.
            if(is.waive(feature_linkage_method)){
              feature_linkage_method <- object@settings$feature_linkage_method
            }
  
            # Obtain feature similarity metric from stored settings, if required.
            if(is.waive(feature_similarity_metric)){
              feature_similarity_metric <- object@settings$feature_similarity_metric
            }
            
            # Replace feature cluster method == "none" with "hclust"
            if(feature_cluster_method == "none"){
              feature_cluster_method <- "hclust"
            }
            
            .check_cluster_parameters(cluster_method=feature_cluster_method,
                                      cluster_linkage=feature_linkage_method,
                                      cluster_similarity_metric=feature_similarity_metric,
                                      var_type="feature")
            
            # Check if any mutual correlation data are available.
            if(is_empty(feature_similarity_table)){
              return(list("data"=NULL,
                          "feature_similarity_metric"=feature_similarity_metric))
            }
            
            # Get the distance matrix from the feature_similarity_table
            distance_matrix <- cluster.get_distance_matrix(similarity_table=feature_similarity_table,
                                                           similarity_metric=feature_similarity_metric)
            
            # Obtain cluster object.
            h <- cluster.get_cluster_object(distance_matrix=distance_matrix,
                                            cluster_method=feature_cluster_method,
                                            cluster_linkage=feature_linkage_method)
            
            # Get data.table with feature ordering
            feature_order_table <- cluster.extract_label_order(cluster_object=h,
                                                               cluster_method=feature_cluster_method)
            
            # Merge ordering into feature_similarity_table. The table is first
            # merged on feature_1 and then on feature_2.
            mutual_correlation_table <- data.table::copy(feature_similarity_table)
            mutual_correlation_table <- merge(x=mutual_correlation_table, y=feature_order_table,
                                              by.x="feature_1", by.y="name", all.x=TRUE, all.y=FALSE)
            mutual_correlation_table <- merge(x=mutual_correlation_table, y=feature_order_table,
                                              by.x="feature_2", by.y="name", all.x=TRUE, all.y=FALSE)
            
            # Rename columns
            data.table::setnames(mutual_correlation_table,
                                 old=c("label_order.x", "label_order.y"),
                                 new=c("label_order_1", "label_order_2"))
            
            # Reorder columns
            data.table::setcolorder(mutual_correlation_table,
                                    c("feature_1", "feature_2", "value", "label_order_1", "label_order_2"))
            
            # Add the name of the ensemble model
            mutual_correlation_table <- add_model_name(data=mutual_correlation_table, object=object)

            return(list("data"=mutual_correlation_table,
                        "feature_similarity_metric"=feature_similarity_metric,
                        "feature_cluster_object"=h))
          })


#'@title Internal function to extract feature expressions.
#'
#'@description Computes and extracts feature expressions for features
#'  used in a `familiarEnsemble` object.
#'
#'@param feature_similarity_table Table containing pairwise distance between
#'  sample. This is used to determine cluster information, and indicate which
#'  samples are similar. The table is created by the
#'  `extract_sample_similarity_table` method.
#'@inheritParams extract_data
#'@inheritParams extract_model_vimp
#'
#'@return A list with a data.table containing feature expressions.
#'@md
#'@keywords internal
setGeneric("extract_feature_expression", function(object,
                                                  data,
                                                  feature_similarity_table,
                                                  sample_similarity_table,
                                                  feature_cluster_method=waiver(),
                                                  feature_linkage_method=waiver(),
                                                  feature_similarity_metric=waiver(),
                                                  sample_cluster_method=waiver(),
                                                  sample_linkage_method=waiver(),
                                                  sample_similarity_metric=waiver(),
                                                  eval_times=waiver(),
                                                  message_indent=0L,
                                                  verbose=FALSE,
                                                  ...) standardGeneric("extract_feature_expression"))

#####extract_feature_expression#####
setMethod("extract_feature_expression", signature(object="familiarEnsemble", data="ANY"),
          function(object,
                   data,
                   feature_similarity_table,
                   sample_similarity_table,
                   feature_cluster_method=waiver(),
                   feature_linkage_method=waiver(),
                   feature_similarity_metric=waiver(),
                   sample_cluster_method=waiver(),
                   sample_linkage_method=waiver(),
                   sample_similarity_metric=waiver(),
                   eval_times=waiver(),
                   message_indent=0L,
                   verbose=FALSE){
            
            # Message extraction start
            if(verbose){
              logger.message(paste0("Computing sample clustering using important features."),
                             indent=message_indent)
            }
            
            # Obtain feature cluster method from stored settings, if required.
            if(is.waive(feature_cluster_method)){
              feature_cluster_method <- object@settings$feature_cluster_method
            }
            
            # Obtain feature linkage function from stored settings, if required.
            if(is.waive(feature_linkage_method)){
              feature_linkage_method <- object@settings$feature_linkage_method
            }
            
            # Obtain feature similarity metric from stored settings, if required.
            if(is.waive(feature_similarity_metric)){
              feature_similarity_metric <- object@settings$feature_similarity_metric
            }
            
            # Replace feature cluster method == "none" with "hclust"
            if(feature_cluster_method == "none"){
              feature_cluster_method <- "hclust"
            }
            
            .check_cluster_parameters(cluster_method=feature_cluster_method,
                                      cluster_linkage=feature_linkage_method,
                                      cluster_similarity_metric=feature_similarity_metric,
                                      var_type="feature")
            
            # Obtain sample cluster method from stored settings, if required.
            if(is.waive(sample_cluster_method)){
              sample_cluster_method <- object@settings$sample_cluster_method
            }
            
            # Obtain sample linkage function from stored settings, if required.
            if(is.waive(sample_linkage_method)){
              sample_linkage_method <- object@settings$sample_linkage_method
            }
            
            # Obtain sample similarity metric from stored settings, if required.
            if(is.waive(sample_similarity_metric)){
              sample_similarity_metric <- object@settings$sample_similarity_metric
            }
            
            # Replace sample cluster method == "none" with "hclust"
            if(sample_cluster_method == "none"){
              sample_cluster_method <- "hclust"
            }
            
            .check_cluster_parameters(cluster_method=sample_cluster_method,
                                      cluster_linkage=sample_linkage_method,
                                      cluster_similarity_metric=sample_similarity_metric,
                                      var_type="sample")

            # Obtain evaluation times from the data.
            if(is.waive(eval_times) & object@outcome_type %in% c("survival", "competing_risk")){
              eval_times <- object@settings$eval_times
              
            } else if(is.waive(eval_times)){
              eval_times <- NULL
            }
            
            # Check if eval_times is correct.
            if(object@outcome_type %in% c("survival", "competing_risk")){
              sapply(eval_times, .check_number_in_valid_range, var_name="eval_times", range=c(0.0, Inf), closed=c(FALSE, TRUE))
            }
            
            # Aggregate data
            data <- aggregate_data(data=data)
            
            # Retrieve input data. Note that we batch_normalisation is taken
            # into account even though the data are converted back to their
            # original scale to derive expressions.
            data <- process_input_data(object=object, data=data, stop_at="batch_normalisation")
            
            if(is_empty(data)) return(NULL)
            
            # Determine signature features
            model_features <- object@model_features
            
            # Maintain only important features. The current set is based on the
            # important features of the model, i.e. those that end up in the
            # model (potentially as a cluster).
            expression_data <- filter_features(data=data, available_features=model_features)
            
            # Perform inverse normalisation
            expression_data <- normalise_features(data=expression_data,
                                                  feature_info_list=object@feature_info,
                                                  invert=TRUE)
            
            # Perform inverse transformation
            expression_data <- transform_features(data=expression_data,
                                                  feature_info_list=object@feature_info,
                                                  invert=TRUE)
            
            # Extract expression data.
            expression_data <- expression_data@data
            
            # Extract feature info list.
            feature_info_list <- object@feature_info[model_features]
            
            # Check if any data are available for ordering features.
            if(!is_empty(feature_similarity_table)){
            
              # Get the distance matrix from the feature_similarity_table
              feature_distance_matrix <- cluster.get_distance_matrix(similarity_table=feature_similarity_table,
                                                                     similarity_metric=feature_similarity_metric)
              
              # Obtain cluster object that identifies similar features.
              h_feature <- cluster.get_cluster_object(distance_matrix=feature_distance_matrix,
                                                      cluster_method=feature_cluster_method,
                                                      cluster_linkage=feature_linkage_method)
              
              # Get data.table with feature ordered according to similarity.
              feature_order_table <- cluster.extract_label_order(cluster_object=h_feature,
                                                                 cluster_method=feature_cluster_method)
            } else {
              # Replacement for empty feature similarity tables
              feature_order_table <- data.table::data.table("name"=object@model_features)
              feature_order_table[, "label_order":=.I]
              
              # Placeholder cluster object
              h_feature <- NULL
            }
            
            # Check if any data are available for ordering samples.
            if(!is_empty(sample_similarity_table)){
            
              # Get the distance matrix from the sample_similarity_table.
              sample_distance_matrix <- cluster.get_distance_matrix(similarity_table=sample_similarity_table,
                                                                    similarity_metric=sample_similarity_metric)
              
              # Obtain cluster object that identifies similar samples.
              h_sample <- cluster.get_cluster_object(distance_matrix=sample_distance_matrix,
                                                     cluster_method=sample_cluster_method,
                                                     cluster_linkage=sample_linkage_method)
              
              # Get data.table with samples ordered according to similarity.
              sample_order_table <- cluster.extract_label_order(cluster_object=h_sample,
                                                                cluster_method=sample_cluster_method)
            } else {
              # Replacement for empty sample similarity tables
              sample_order_table <- data.table::data.table("sample_name"=get_unique_row_names(expression_data))
              sample_order_table[, "label_order":=.I]
              
              # Placeholder cluster object
              h_sample <- NULL
            }
            
            # Add sample_name to expression_data
            row_names <- get_unique_row_names(expression_data)
            expression_data[, ":="("sample_name"=row_names, "batch_id"=NULL, "sample_id"=NULL, "series_id"=NULL, "repetition_id"=NULL)]
            
            # Add model name.
            expression_data <- add_model_name(data=expression_data, object=object)
            
            # Store to list. Note that the normalisation parameters are the
            # general normalisation parameter, not batch-normalisation parameters.
            expression_info <- list("expression_data"=expression_data,
                                    "feature_info"=feature_info_list,
                                    "feature_similarity_metric"=feature_similarity_metric,
                                    "feature_cluster_object"=h_feature,
                                    "feature_order"=feature_order_table,
                                    "sample_similarity_metric"=sample_similarity_metric,
                                    "sample_cluster_object"=h_sample,
                                    "sample_order"=sample_order_table,
                                    "evaluation_times"=eval_times)
            
            return(expression_info)
          })







#'@title Internal function to extract the feature distance table.
#'
#'@description Computes and extracts the feature distance table for features
#'  used in a `familiarEnsemble` object. This table can be used to cluster
#'  features, and is exported directly by `extract_mutual_correlation`.
#'
#'@inheritParams extract_data
#'
#'@return A data.table containing pairwise distance between features. This data
#'  is only the upper triangular of the complete matrix (i.e. the sparse
#'  unitriangular representation). Diagonals will always be 0.0 and the lower
#'  triangular is mirrored.
#'@md
#'@keywords internal
setGeneric("extract_feature_similarity_table", function(object,
                                                        data,
                                                        cl=NULL,
                                                        feature_similarity_metric=waiver(),
                                                        verbose=FALSE,
                                                        message_indent=0L,
                                                        ...) standardGeneric("extract_feature_similarity_table"))

#####extract_feature_similarity_table#####
setMethod("extract_feature_similarity_table", signature(object="familiarEnsemble", data="ANY"),
          function(object,
                   data,
                   cl=NULL,
                   feature_similarity_metric=waiver(),
                   verbose=FALSE,
                   message_indent=0L){
            
            # Message extraction start
            if(verbose){
              logger.message(paste0("Computing pairwise similarity for important features."), indent=message_indent)
            }
            
            # Obtain similarity metric from stored settings, if required.
            if(is.waive(feature_similarity_metric)){
              feature_similarity_metric <- object@settings$feature_similarity_metric
            }
            
            # Check correlation method
            .check_parameter_value_is_valid(x=feature_similarity_metric, var_name="feature_similarity_metric",
                                            values=.get_available_similarity_metrics(data_type="feature"))
            
            # Define an empty table prototype
            empty_similarity_table <- data.table::data.table("feature_1"=character(0),
                                                           "feature_2"=character(0),
                                                           "value"=numeric(0))
            
            # Retrieve input data.
            data <- process_input_data(object=object, data=data, stop_at="imputation")
            
            # Check if the input data is not empty
            if(is_empty(data)) return(empty_similarity_table)
            
            # Check if the number of samples is sufficient (>5), and return an
            # empty table if not.
            if(data.table::uniqueN(data@data, by=get_id_columns(id_depth="series")) <= 5) return(empty_similarity_table)
            
            # Maintain only important features. The current set is based on the
            # required features.
            data <- filter_features(data=data, available_features=object@model_features)
            
            # Identify eligible columns.
            feature_columns <- get_feature_columns(x=data)
            
            # Break if there are not at least 2 features present between which
            # correlation can be compared.
            if(length(feature_columns) < 2) {
              return(empty_similarity_table)
            }
            
            # Compute the similarity table
            feature_similarity_table <- cluster.get_featurewise_similarity_table(cl=cl,
                                                                                 data_obj=data,
                                                                                 feature_columns=feature_columns,
                                                                                 similarity_metric=feature_similarity_metric,
                                                                                 verbose=verbose,
                                                                                 message_indent=message_indent + 1L)
            
            return(feature_similarity_table)
          })



#'@title Internal function to extract the sample distance table.
#'
#'@description Computes and extracts the sample distance table for samples
#'  analysed using a `familiarEnsemble` object to form a `familiarData` object. This table can be used to cluster
#'  samples, and is exported directly by `extract_feature_expression`.
#'
#'@inheritParams extract_data
#'
#'@return A data.table containing pairwise distance between samples. This data
#'  is only the upper triangular of the complete matrix (i.e. the sparse
#'  unitriangular representation). Diagonals will always be 0.0 and the lower
#'  triangular is mirrored.
#'@md
#'@keywords internal
setGeneric("extract_sample_similarity_table", function(object,
                                                       data,
                                                       cl=NULL,
                                                       sample_similarity_metric=waiver(),
                                                       message_indent=0L,
                                                       verbose=FALSE,
                                                       ...) standardGeneric("extract_sample_similarity_table"))

#####extract_sample_similarity_table#####
setMethod("extract_sample_similarity_table", signature(object="familiarEnsemble", data="ANY"),
          function(object,
                   data,
                   cl=NULL,
                   sample_similarity_metric=waiver(),
                   message_indent=0L,
                   verbose=FALSE){
            
            # Message extraction start
            if(verbose){
              logger.message(paste0("Computing pairwise similarity between samples."), indent=message_indent)
            }
            
            # Obtain similarity metric from stored settings, if required.
            if(is.waive(sample_similarity_metric)){
              sample_similarity_metric <- object@settings$sample_similarity_metric
            }
            
            # Check correlation method
            .check_parameter_value_is_valid(x=sample_similarity_metric, var_name="sample_similarity_metric",
                                            values=.get_available_similarity_metrics(data_type="sample"))
            
            # Define an empty table prototype
            empty_similarity_table <- data.table::data.table("sample_1"=character(0),
                                                             "sample_2"=character(0),
                                                             "value"=numeric(0))
            
            # Retrieve input data.
            data <- process_input_data(object=object, data=data, stop_at="imputation")
            
            # Check if the input data is not empty
            if(is_empty(data)) return(empty_similarity_table)
            
            # Check if the number of samples is sufficient to form pairs (>= 2),
            # and return an empty table if not.
            if(data.table::uniqueN(data@data, by=get_id_columns(id_depth="series")) < 2) return(empty_similarity_table)
            
            # Maintain only important features. The current set is based on the
            # required features.
            data <- filter_features(data=data, available_features=object@model_features)
            
            # Aggregate features.
            data <- aggregate_data(data=data)
            
            # Identify eligible columns
            feature_columns <- get_feature_columns(x=data)
            
            # Break if there are is not at least 1 feature present between which
            # similarity can be compared between samples.
            if(length(feature_columns) < 2) return(empty_similarity_table)
            
            # Compute the similarity table
            sample_similarity_table <- cluster.get_samplewise_similarity_table(cl=cl,
                                                                               data=data,
                                                                               similarity_metric=sample_similarity_metric,
                                                                               verbose=verbose,
                                                                               message_indent=message_indent + 1L)
            
            return(sample_similarity_table)
          })
