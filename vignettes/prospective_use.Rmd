---
title: "Using familiar prospectively"
author: "Alex Zwanenburg"
date: "`r Sys.Date()`"
output:
  rmarkdown::html_vignette:
    includes:
      after_body: license.html
bibliography: "refs.bib"
vignette: >
  %\VignetteIndexEntry{Using familiar prospectively}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup, results=FALSE}
library(familiar)
library(data.table)

set.seed(19)
```

The `summon_familiar` function is used to generate models for a given dataset
and provide a broad analysis afterwards. Many of the files resulting from this
analysis can also be used outside of `summon_familiar`. For example models and
ensembles can be used prospectively to assess new datasets. Likewise data and
collection objects can be used to customise plotting and export to tables.

In this example we will use the Iris dataset, which we first randomly split into
development and validation datasets:

```{r, results=FALSE}
# Load Iris data set
data <- data.table::as.data.table(iris)

# Add sample and cohort id
data[,":="("sample_id"=.I)]

# Generate training and validation samples
train_samples <- sample(data$sample_id, size=100, replace=FALSE)
valid_samples <- setdiff(data$sample_id, train_samples)

# Assign batch identifiers.
data[sample_id %in% train_samples, "batch_id":="development"]
data[sample_id %in% valid_samples, "batch_id":="validation"]
```

Then we summon our familiar to create models for the data, and assess it. We
will create five multinomial logistic regression models to predict the iris
species, based on bootstraps of the development dataset. You may notice that we
here write to the temporary R directory using `tempdir()`. In practice you will
want to use a different directory, as the temporary R directory will be removed
once your R session closes. For speed, we will also only compute point estimates
during evaluation.

```{r, results="hide", message=FALSE, warning=FALSE}
familiar::summon_familiar(data=data,
                          project_dir=tempdir(),
                          sample_id_column="sample_id",
                          batch_id_column="batch_id",
                          development_batch_id="development",
                          outcome_type="multinomial",
                          outcome_column="Species",
                          experimental_design="bt(fs+mb,5) + ev",
                          cluster_method="none",
                          fs_method="mrmr",
                          learner="glm",
                          parallel=FALSE,
                          estimation_type="point")
```

# Using models prospectively

Models generated by familiar are stored in subdirectories of the
`trained_models` folder:

```{r}
# Create path to the directory containing the models.
model_directory_path <- file.path(tempdir(), "trained_models", "glm", "mrmr")

# List files present in the directory.
list.files(model_directory_path)
```

There are 5 models in the directory, which are stored in RDS format in files
ending with `*_model.RDS`. We can inspect the first model in the directory.

```{r}
# Create path to the model.
model_path <- file.path(model_directory_path, list.files(model_directory_path, pattern="model")[1])

# Load the model.
model <- readRDS(model_path)
model
```

This model can then be used to predict values for a given dataset, among other
things:

```{r}
# To be implemented.
```

More powerful however, is the ability to perform any of the evaluation and
explanation steps for a new dataset, including new settings. By default all
evaluation and explanation steps are conducted using the settings defined when
running `summon_familiar`. In this case that means that point estimates will be
computed.

Let us for example compute and plot model performance AUC-ROC and accuracy for
the model.

```{r}
plots <- familiar::plot_model_performance(object=model,
                                          draw=TRUE,
                                          facet_by="metric",
                                          data=data[batch_id=="validation"],
                                          metric=c("auc", "accuracy"))
```

You may notice that no plot is produced. This is because the type of plot
`"violin_plot"` and the `estimation_type` inherited from the model are
incompatible. However, nothing prevents us from changing the estimation type.

```{r}
# Draw model performance plots with bootstrap confidence intervals. familiar_data_names argument specifies the name that appears below the plot. The default is rather long.
plots <- familiar::plot_model_performance(object=model,
                                          draw=TRUE,
                                          facet_by="metric",
                                          data=data[batch_id=="validation"],
                                          estimation_type="bci",
                                          metric=c("auc", "accuracy"),
                                          familiar_data_names="GLM")
```

Note that we can achieve the same result without explicitly importing the model.
Providing the path to the model as the `object` argument suffices:

```{r}
plots <- familiar::plot_model_performance(object=model_path,
                                          draw=TRUE,
                                          facet_by="metric",
                                          data=data[batch_id=="validation"],
                                          estimation_type="bci",
                                          metric=c("auc", "accuracy"),
                                          familiar_data_names="GLM")
```

# Using ensembles of models prospectively

The five models created in the example form an ensemble. Instead of
investigating the models separately, we can

# Custom exports and plots

