% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/FamiliarCollectionExport.R
\name{export_permutation_vimp}
\alias{export_permutation_vimp}
\alias{export_permutation_vimp,familiarCollection-method}
\alias{export_permutation_vimp,ANY-method}
\title{Extract and export permutation variable importance.}
\usage{
export_permutation_vimp(object, dir_path = NULL, ...)

\S4method{export_permutation_vimp}{familiarCollection}(object, dir_path = NULL, export_raw = FALSE, ...)

\S4method{export_permutation_vimp}{ANY}(object, dir_path = NULL, export_raw = FALSE, ...)
}
\arguments{
\item{object}{A \code{familiarCollection} object, or other other objects from which
a \code{familiarCollection} can be extracted. See details for more information.}

\item{dir_path}{Path to folder where extracted data should be saved. \code{NULL}
will allow export as a structured list of data.tables.}

\item{...}{
  Arguments passed on to \code{\link[=extract_permutation_vimp]{extract_permutation_vimp}}, \code{\link[=as_familiar_collection]{as_familiar_collection}}
  \describe{
    \item{\code{data}}{A \code{dataObject} object, \code{data.table} or \code{data.frame} that
constitutes the data that are used to compute}
    \item{\code{cl}}{Cluster created using the \code{parallel} package. This cluster is then
used to speed up computation through parallelisation.}
    \item{\code{metric}}{One or more metrics for assessing model performance. See the
vignette on performance metrics for the available metrics. If not provided
explicitly, this parameter is read from settings used at creation of the
underlying \code{familiarModel} objects.}
    \item{\code{ensemble_method}}{Method for ensembling predictions from models for the
same sample. Available methods are:
\itemize{
\item \code{mean}: Use the mean of the predicted values as the ensemble value for a
sample.
}}
    \item{\code{eval_times}}{One or more time points that are used for assessing
calibration in survival problems. This is done as expected and observed
survival probabilities depend on time. If not provided explicitly, this
parameter is read from settings used at creation of the underlying
\code{familiarModel} objects. Only used for \code{survival} outcomes.}
    \item{\code{confidence_level}}{(\emph{optional}) Numeric value for the level at which
confidence are determined. In the case bootstraps are used to determine the
confidence intervals bootstrap estimation, \code{familiar} uses the rule of thumb
\eqn{n = 20 / ci.level} to determine the number of required bootstraps.

If not provided explicitly, this parameter is read from settings used at
creation of the underlying \code{familiarModel} objects.

#'@param confidence_level (\emph{optional}) Numeric value for the level at which
confidence are determined. In the case bootstraps are used to determine the
confidence intervals bootstrap estimation, \code{familiar} uses the rule of thumb
\eqn{n = 20 / ci.level} to determine the number of required bootstraps.

The default value is \code{0.95}.}
    \item{\code{bootstrap_ci_method}}{(\emph{optional}) Method used to determine bootstrap
confidence intervals (Efron and Hastie, 2016). The following methods are
implemented:
\itemize{
\item \code{percentile}: Confidence intervals obtained using the percentile method.
\item \code{bc} (default): Bias-corrected confidence intervals.
}

Note that the standard method is not implemented because this method is
often not suitable due to non-normal distributions. The bias-corrected and
accelerated method is not implemented yet.}
    \item{\code{aggregate_ci}}{(\emph{optional}) Bootstraps are used to determine confidence
intervals. This information can be stored for export. However, in many cases
this is not necessary, and keeping the bootstrap data can lead to large
\code{familiarData} and \code{familiarCollection} objects. This provides the option to
aggregate the bootstrap data by computing the confidence interval directly.

This parameter can take one or more of the following values: \code{all},
\code{model_performance}, \code{auc_data}, \code{decision_curve_analyis}, as well as
\code{true}, \code{false} and \code{none}. By default, bootstrap data is aggregated by
computing confidence intervals for receiver-operating characteristic curves
and decision curves.}
    \item{\code{is_pre_processed}}{Flag that indicates whether the data was already
pre-processed externally, e.g. normalised and clustered. Only used if the
\code{data} argument is a \code{data.table} or \code{data.frame}.}
    \item{\code{message_indent}}{Number of indentation steps for messages shown during
computation and extraction of various data elements.}
    \item{\code{verbose}}{Flag to indicate whether feedback should be provided on the
computation and extraction of various data elements.}
    \item{\code{familiar_data_names}}{Names of the dataset(s). Only used if the \code{object} parameter
is one or more \code{familiarData} objects.}
    \item{\code{collection_name}}{Name of the collection.}
  }}

\item{export_raw}{Allows export of raw data. Only used when exporting model
performance information.}
}
\value{
A data.table (if \code{dir_path} is not provided), or nothing, as all data
is exported to \code{csv} files.
}
\description{
Extract and export model-based variable importance from a
familiarCollection.
}
\details{
Data, such as permutation variable importance and calibration
information, is usually collected from a \code{familiarCollection} object.
However, you can also provide one or more \code{familiarData} objects, that will
be internally converted to a \code{familiarCollection} object. It is also
possible to provide a \code{familiarEnsemble} or one or more \code{familiarModel}
objects together with the data from which data is computed prior to export.
Paths to the previously mentioned files can also be provided.

All parameters aside from \code{object} and \code{dir_path} are only used if \code{object}
is not a \code{familiarCollection} object, or a path to one.

Permutation Variable importance assesses the improvement in model
performance due to a feature. For this purpose, the performance of the model
is measured as normal, and is measured again with a dataset where the values
of the feature in question have been randomly permuted. The difference
between both performance measurements is the permutation variable
importance.

In familiar, this basic concept is extended in several ways:
\itemize{
\item Point estimates of variable importance are based on multiple (21) random
permutations. The difference between model performance on the normal dataset
and the median performance measurement of the randomly permuted datasets is
used as permutation variable importance.
\item Confidence intervals for the ensemble model are determined using bootstrap
methods.
\item Permutation variable importance is assessed for any metric specified using
the \code{metric} argument.
\item Permutation variable importance can take into account similarity between
features and permute similar features simultaneously.
}
}
