% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/FamiliarCollectionExport.R
\name{export_all}
\alias{export_all}
\alias{export_all,familiarCollection-method}
\alias{export_all,ANY-method}
\title{Extract and export all data.}
\usage{
export_all(object, dir_path = NULL, export_raw = FALSE, ...)

\S4method{export_all}{familiarCollection}(object, dir_path = NULL, export_raw = FALSE, ...)

\S4method{export_all}{ANY}(object, dir_path = NULL, export_raw = FALSE, ...)
}
\arguments{
\item{object}{A \code{familiarCollection} object, or other other objects from which
a \code{familiarCollection} can be extracted. See details for more information.}

\item{dir_path}{Path to folder where extracted data should be saved. \code{NULL}
will allow export as a structured list of data.tables.}

\item{export_raw}{Allows export of raw data. Only used when exporting model
performance information.}

\item{...}{
  Arguments passed on to \code{\link[=extract_data]{extract_data}}, \code{\link[=as_familiar_collection]{as_familiar_collection}}
  \describe{
    \item{\code{data}}{A \code{dataObject} object, \code{data.table} or \code{data.frame} that
constitutes the data that are used to compute}
    \item{\code{is_pre_processed}}{Flag that indicates whether the data was already
pre-processed externally, e.g. normalised and clustered. Only used if the
\code{data} argument is a \code{data.table} or \code{data.frame}.}
    \item{\code{cl}}{Cluster created using the \code{parallel} package. This cluster is then
used to speed up computation through parallelisation.}
    \item{\code{time_max}}{Time point which is used as the benchmark for e.g. cumulative
risks generated by random forest, or the cutoff for Uno's concordance index.
If not provided explicitly, this parameter is read from settings used at
creation of the underlying \code{familiarModel} objects. Only used for \code{survival}
outcomes.}
    \item{\code{eval_times}}{One or more time points that are used for assessing
calibration in survival problems. This is done as expected and observed
survival probabilities depend on time. If not provided explicitly, this
parameter is read from settings used at creation of the underlying
\code{familiarModel} objects. Only used for \code{survival} outcomes.}
    \item{\code{aggregation_method}}{Method for aggregating variable importances for the
purpose of evaluation. Variable importances are determined during feature
selection steps and after training the model. Both types are evaluated, but
feature selection variable importance is only evaluated at run-time.

See the documentation for the \code{vimp_aggregation_method} argument in
\code{summon_familiar} for information concerning the different available
methods.

If not provided explicitly, this parameter is read from settings used at
creation of the underlying \code{familiarModel} objects.}
    \item{\code{rank_threshold}}{The threshold used to  define the subset of highly
important features during evaluation.

See the documentation for the \code{vimp_aggregation_rank_threshold} argument in
\code{summon_familiar} for more information.

If not provided explicitly, this parameter is read from settings used at
creation of the underlying \code{familiarModel} objects.}
    \item{\code{ensemble_method}}{Method for ensembling predictions from models for the
same sample. Available methods are:
\itemize{
\item \code{mean}: Use the mean of the predicted values as the ensemble value for a
sample.
}}
    \item{\code{stratification_ensemble_method}}{Method for ensembling the risk group
assignments from different models for the same sample.

The following methods are available:
\itemize{
\item \code{ensemble_mean}: Risk groups are determined for each sample using the
threshold values of the different models in the ensemble. The risk groups
are treated as ordinal and encoded using integer values. The mean of the
encoded values is computed. The risk group bin containing the mean value is
then used as the ensemble-based risk group.
\item \code{ensemble_mode} (default): Risk groups are determined for each sample
using the threshold values of the different models in the ensemble. The most
commonly assigned risk group is then used as the ensemble-based risk group.
\item \code{median_threshold}: The median threshold value for each risk group is
determined from the threshold values of the different models in the
ensemble. The resulting threshold(s) are then applied to the ensemble
prediction of a sample to identify the ensemble-based risk group.
\item \code{mean_threshold}: Similar to \code{median_threshold}, but uses the mean
threshold value for each risk group.
}

If not provided explicitly, this parameter is read from settings used at
creation of the underlying \code{familiarModel} objects. This parameter is only
relevant for \code{survival} outcomes.}
    \item{\code{metric}}{One or more metrics for assessing model performance. See the
vignette on performance metrics for the available metrics. If not provided
explicitly, this parameter is read from settings used at creation of the
underlying \code{familiarModel} objects.}
    \item{\code{feature_cluster_method}}{The method used to perform clustering. These are
the same methods as for the \code{cluster_method} configuration parameter:
\code{none}, \code{hclust}, \code{agnes}, \code{diana} and \code{pam}.

\code{none} cannot be used when extracting data regarding mutual correlation or
feature expressions.

If not provided explicitly, this parameter is read from settings used at
creation of the underlying \code{familiarModel} objects.}
    \item{\code{feature_linkage_method}}{The method used for agglomerative clustering in
\code{hclust} and \code{agnes}. These are the same methods as for the
\code{cluster_linkage_method} configuration parameter: \code{average}, \code{single},
\code{complete}, \code{weighted}, and \code{ward}.

If not provided explicitly, this parameter is read from settings used at
creation of the underlying \code{familiarModel} objects.}
    \item{\code{feature_cluster_cut_method}}{The method used to divide features into
separate clusters. The available methods are the same as for the
\code{cluster_cut_method} configuration parameter: \code{silhouette}, \code{fixed_cut} and
\code{dynamic_cut}.

\code{silhouette} is available for all cluster methods, but \code{fixed_cut} only
applies to methods that create hierarchical trees (\code{hclust}, \code{agnes} and
\code{diana}). \code{dynamic_cut} requires the \code{dynamicTreeCut} package and can only
be used with \code{agnes} and \code{hclust}.

If not provided explicitly, this parameter is read from settings used at
creation of the underlying \code{familiarModel} objects.}
    \item{\code{feature_similarity_threshold}}{The threshold level for pair-wise
similarity that is required to form feature clusters with the \code{fixed_cut}
method.

If not provided explicitly, this parameter is read from settings used at
creation of the underlying \code{familiarModel} objects.}
    \item{\code{feature_similarity_metric}}{Metric to determine pairwise similarity
between features. Similarity is computed in the same manner as for
clustering, and \code{feature_similarity_metric} therefore has the same options
as \code{cluster_similarity_metric}: \code{mcfadden_r2}, \code{cox_snell_r2},
\code{nagelkerke_r2}, \code{spearman}, \code{kendall} and \code{pearson}.

If not provided explicitly, this parameter is read from settings used at
creation of the underlying \code{familiarModel} objects.}
    \item{\code{sample_cluster_method}}{The method used to perform clustering based on
distance between samples. These are the same methods as for the
\code{cluster_method} configuration parameter: \code{hclust}, \code{agnes}, \code{diana} and
\code{pam}.

\code{none} cannot be used when extracting data for feature expressions.

If not provided explicitly, this parameter is read from settings used at
creation of the underlying \code{familiarModel} objects.}
    \item{\code{sample_linkage_method}}{The method used for agglomerative clustering in
\code{hclust} and \code{agnes}. These are the same methods as for the
\code{cluster_linkage_method} configuration parameter: \code{average}, \code{single},
\code{complete}, \code{weighted}, and \code{ward}.

If not provided explicitly, this parameter is read from settings used at
creation of the underlying \code{familiarModel} objects.}
    \item{\code{sample_similarity_metric}}{Metric to determine pairwise similarity
between samples. Similarity is computed in the same manner as for
clustering, but \code{sample_similarity_metric} has different options that are
better suited to computing distance between samples instead of between
features: \code{gower}, \code{euclidean}.

The underlying feature data is scaled to the \eqn{[0, 1]} range (for
numerical features) using the feature values across the samples. The
normalisation parameters required can optionally be computed from feature
data with the outer 5\% (on both sides) of feature values trimmed or
winsorised. To do so append \verb{_trim} (trimming) or \verb{_winsor} (winsorising) to
the metric name. This reduces the effect of outliers somewhat.

If not provided explicitly, this parameter is read from settings used at
creation of the underlying \code{familiarModel} objects.}
    \item{\code{icc_type}}{String indicating the type of intraclass correlation
coefficient (\code{1}, \code{2} or \code{3}) that should be used to compute robustness for
features in repeated measurements during the evaluation of univariate
importance. These types correspond to the types in Shrout and Fleiss (1979).
If not provided explicitly, this parameter is read from settings used at
creation of the underlying \code{familiarModel} objects.}
    \item{\code{verbose}}{Flag to indicate whether feedback should be provided on the
computation and extraction of various data elements.}
    \item{\code{message_indent}}{Number of indentation steps for messages shown during
computation and extraction of various data elements.}
    \item{\code{data_element}}{String indicating which data elements are to be extracted.
Default is \code{all}, but specific elements can be specified to speed up
computations if not all elements are to be computed. This is an internal
parameter that is set by, e.g. the \code{export_model_vimp} method.}
    \item{\code{confidence_level}}{(\emph{optional}) Numeric value for the level at which
confidence intervals are determined. In the case bootstraps are used to
determine the confidence intervals bootstrap estimation, \code{familiar} uses the
rule of thumb \eqn{n = 20 / ci.level} to determine the number of required
bootstraps.

The default value is \code{0.95}.}
    \item{\code{bootstrap_ci_method}}{(\emph{optional}) Method used to determine bootstrap
confidence intervals (Efron and Hastie, 2016). The following methods are
implemented:
\itemize{
\item \code{percentile}: Confidence intervals obtained using the percentile method.
\item \code{bc} (default): Bias-corrected confidence intervals.
}

Note that the standard method is not implemented because this method is
often not suitable due to non-normal distributions. The bias-corrected and
accelerated (BCa) method is not implemented yet.}
    \item{\code{compute_model_ci}}{(\emph{optional}) This parameter can be set to enable
computation of bootstrap confidence intervals for individual models in
several parts of the evaluation. The parameter can take one or more of the
following values: \code{all}, \code{model_performance}, \code{auc_data},
\code{decision_curve_analyis}, \code{permutation_vimp} as well as \code{true}, \code{false} and
\code{none}.

By default, bootstrap confidence intervals are not computed for individual
models.}
    \item{\code{compute_ensemble_ci}}{(\emph{optional}) This parameter can be set to enable
computation of bootstrap confidence intervals for ensemble models in
several parts of the evaluation. The parameter can take one or more of the
following values: \code{all}, \code{model_performance}, \code{auc_data},
\code{decision_curve_analyis}, \code{permutation_vimp} as well as \code{true}, \code{false} and
\code{none}.

By default, bootstrap confidence intervals are computed for ensemble
models.}
    \item{\code{aggregate_ci}}{(\emph{optional}) Bootstraps are used to determine confidence
intervals. This information can be stored for export. However, in many cases
this is not necessary, and keeping the bootstrap data can lead to large
\code{familiarData} and \code{familiarCollection} objects. This provides the option to
aggregate the bootstrap data by computing the confidence interval directly.

This parameter can take one or more of the following values: \code{all},
\code{model_performance}, \code{auc_data}, \code{decision_curve_analyis},
\code{permutation_vimp} as well as \code{true}, \code{false} and \code{none}. By default,
bootstrap data is aggregated by computing confidence intervals for
receiver-operating characteristic curves, decision curves and permutation
variable importance.}
    \item{\code{familiar_data_names}}{Names of the dataset(s). Only used if the \code{object} parameter
is one or more \code{familiarData} objects.}
    \item{\code{collection_name}}{Name of the collection.}
  }}
}
\value{
A list of data.tables (if \code{dir_path} is not provided), or nothing, as
all data is exported to \code{csv} files.
}
\description{
Extract and export all data from a familiarCollection.
}
\details{
Data, such as model performance and calibration information, is
usually collected from a \code{familiarCollection} object. However, you can also
provide one or more \code{familiarData} objects, that will be internally
converted to a \code{familiarCollection} object. It is also possible to provide a
\code{familiarEnsemble} or one or more \code{familiarModel} objects together with the
data from which data is computed prior to export. Paths to the previous
files can also be provided.

All parameters aside from \code{object} and \code{dir_path} are only used if \code{object}
is not a \code{familiarCollection} object, or a path to one.
}
