% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/ParseSettings.R
\name{.parse_hyperparameter_optimisation_settings}
\alias{.parse_hyperparameter_optimisation_settings}
\title{Internal function for parsing settings related to model hyperparameter
optimisation}
\usage{
.parse_hyperparameter_optimisation_settings(
  config = NULL,
  parallel,
  outcome_type,
  optimisation_bootstraps = waiver(),
  smbo_random_initialisation = waiver(),
  max_smbo_iterations = waiver(),
  smbo_stop_convergent_iterations = waiver(),
  smbo_step_bootstraps = waiver(),
  smbo_intensify_steps = waiver(),
  smbo_intensify_stop_p_value = waiver(),
  objective = waiver(),
  optimisation_metric = waiver(),
  parallel_hyperparameter_optimisation = waiver(),
  ...
)
}
\arguments{
\item{config}{A list of settings, e.g. from an xml file.}

\item{parallel}{Logical value that whether familiar uses parallelisation. If
\code{FALSE} it will override \code{parallel_hyperparameter_optimisation}.}

\item{outcome_type}{Type of outcome found in the data set.}

\item{optimisation_bootstraps}{(\emph{optional}) Number of bootstraps that should
be generated from the development data set. During the optimisation
procedure one or more of these bootstraps (indicated by
\code{smbo_step_bootstraps}) are used for model development using different
combinations of hyperparameters. The effect of the hyperparameters is then
assessed by comparing in-bag and out-of-bag model performance.

The default number of bootstraps is \code{200}. Hyperparameter optimisation may
finish before exhausting the set of boostraps.}

\item{smbo_random_initialisation}{(\emph{optional}) Logical indicating random
(\code{TRUE}) or grid-based (\code{FALSE}) initialisation of combinations of
hyperparameters. If random initialisation is selected, up to 200 unique
combinations will be randomly generated and assessed during the initial
step of the sequential model-based boosting (SMBO) algorithm (Hutter et
al., 2011). If a grid-based initialisation is selected, up to 100
permutations will be randomly selected from the complete parameter grid and
assessed during the initial SMBO step.

The default is \code{TRUE} (random initialisation). Grid-based initialisation
uses pre-defined parameter ranges.}

\item{max_smbo_iterations}{(\emph{optional}) Maximum number of intensify
iterations of the SMBO algorithm. During an intensify iteration a run-off
occurs between the current \emph{best} hyperparameter combination and either 10
challenger combination with the highest expected improvement or a set of 20
random combinations.

Run-off with random combinations is used to force exploration of the
hyperparameter space, and is performed every second intensify iteration, or
if there is no expected improvement for any challenger combination.

If a combination of hyperparameters leads to better performance on the same
data than the incumbent \emph{best} set of hyperparameters, it replaces the
incumbent set at the end of the intensify iteration.

The default number of intensify iteration is \code{30}. Iterations may be
stopped early if the incumbent set of hyperparameters remains the same for
\code{smbo_stop_convergent_iterations} iterations, or performance improvement is
minimal. This behaviour is suppressed during the first 4 iterations to
enable the algorithm to explore the hyperparameter space.}

\item{smbo_stop_convergent_iterations}{(\emph{optional}) The number of subsequent
convergent SMBO iterations required to stop hyperparameter optimisation
early. The default value is \code{3}.}

\item{smbo_step_bootstraps}{(\emph{optional}) The number of bootstraps taken from
the set of \code{optimisation_bootstraps} bootstraps as data for the initial
SMBO step and the steps in each intensify iteration.

The default value is \code{5}. The value cannot be larger than
\code{optimisation_bootstraps}.}

\item{smbo_intensify_steps}{(\emph{optional}) The number of steps in each SMBO
intensify iteration. Each step a new set of \code{smbo_step_bootstraps}
bootstraps is drawn and used in the run-off between the incumbent \emph{best}
hyperparameter combination and its challengers.

The default value is \code{3}. Higher numbers allow for a more detailed
comparison, but this comes with added computational cost.}

\item{smbo_intensify_stop_p_value}{(\emph{optional}) The p-value threshold which
is used to test the hypothesis that a challenger hyperparameter set and the
incumbent set have the same performance. A paired Wilcoxon test is
performed, with the alternative hypothesis that the challenger set is less
performant.

The p-value from the test is compared to \code{smbo_intensify_stop_p_value} and
if it is found lower, the challenger set is eliminated and not used in any
further intensify steps during the current iteration. Elimination of sets
of hyperparameters that are unlikely to lead to better models improves
computational efficiency.

The default value is \code{0.05}.}

\item{objective}{(\emph{optional}) Type of objective used to determine the
performance of a hyperparameter set. Model performance is assessed using
the metric specified by \code{optimisation_metric} on the in-bag and out-of-bag
samples of a bootstrap. These will be referred to as \eqn{s_{ib}} and
\eqn{s_{oob}}, respectivily. The method indicated by \code{objective} computes a
objective score from each pair of values. The following objective methods
are available:
\itemize{
\item \code{max_validation}: Uses the out-of-bag validation score \eqn{s_{oob}} as
objective. This is a standard machine learning objective.
\item \code{balanced} (default): Computes \eqn{s_{oob} - |s_{oob} - s_{ib}|}. This
objective forces the algorithm to consider hyperparameter sets that perform
well on both development and validation data.
\item \code{stronger_balance}: Computes \eqn{s_{oob} - 2.0 |s_{oob} - s_{ib}|}.
Stronger penalty than in the \code{balance} objective.
}}

\item{optimisation_metric}{(\emph{optional}) One or more metrics used to compute
performance scores. See the vignette on performance metrics for the
available metrics.

If unset, the following metrics are used by default:
\itemize{
\item \code{auc_roc}: For \code{binomial} and \code{multinomial} models.
\item \code{mse}: Mean squared error for \code{continuous} models.
\item \code{msle}: Mean squared logarithmic error for \code{count} models.
\item \code{concordance_index}: For \code{survival} models.
}

Multiple optimisation metrics can be specified. Actual metric values are
converted to an objective value by comparison with a baseline metric value
that derives from a trivial model, i.e. majority class for binomial and
multinomial outcomes, the median outcome for count and continuous outcomes
and a fixed risk or time for survival outcomes.}

\item{parallel_hyperparameter_optimisation}{(\emph{optional}) Enable parallel
processing for hyperparameter optimisation. Defaults to \code{TRUE}. When set to
\code{FALSE}, this will disable the use of parallel processing while performing
optimisation, regardless of the settings of the \code{parallel} parameter.
\code{parallel_hyperparameter_optimisation} is ignored if \code{parallel=FALSE}.}

\item{...}{Unused arguments.}
}
\value{
List of parameters related to model hyperparameter optimisation.
}
\description{
Internal function for parsing settings related to model hyperparameter
optimisation
}
\references{
\enumerate{
\item Hutter, F., Hoos, H. H. & Leyton-Brown, K. Sequential
model-based optimization for general algorithm configuration. in Learning
and Intelligent Optimization (ed. Coello, C. A. C.) 6683, 507â€“523 (Springer
Berlin Heidelberg, 2011).
}
}
\keyword{internal}
